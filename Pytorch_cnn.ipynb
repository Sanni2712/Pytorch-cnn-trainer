{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GCWEjh4m-Jxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sympy==1.11.1  #only and only if the imports dont work even after restarting runtime, otherwise skip this."
      ],
      "metadata": {
        "id": "kT0szMgz-1A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi                 #Free T4 GPU runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbAOqJZH0WJn",
        "outputId": "1f6b012c-1929-4dcd-d74b-75d428f5d1c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 21 10:31:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training phase"
      ],
      "metadata": {
        "id": "vxJb1FuLiBZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UlN4Km088B2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformer = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),   # Resize to uniform size\n",
        "    transforms.ToTensor(),           # Convert to tensor\n",
        "])"
      ],
      "metadata": {
        "id": "-k_-L95X9Z1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=\"dataset\", transform=img_transformer)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "print(\"\\nDetected Classes:\", dataset.classes)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cGTvJGgf9fVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "save_model_name = input(\"Save the model as: _______.pth: \")\n",
        "\n",
        "l_r = 0.001\n",
        "try:\n",
        "    l_r = float(input(\"\\n\\033[34mLearning rate [default lr=0.001]\\033[0m \\nthis value controls how big a step the optimizer takes when updating model weights during training.\\nLess the lr value more the training time, more the accuracy\\nEnter the lr value or simply press enter to proceed with default value: \"))\n",
        "except:\n",
        "    l_r = 0.001\n",
        "try:\n",
        "   epc = int(input(\"\\n\\033[34mEpochs [default: 10]\\033[0m \\n(An epoch is one complete pass through the entire training dataset by the model)\\nEnter the number of epochs to execute or simply press enter to proceed with default value: \"))\n",
        "except:\n",
        "   epc = 10\n"
      ],
      "metadata": {
        "id": "0Xy0xjpq9k9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CardCNN(nn.Module):\n",
        "    def __init__(self, num_classes,  colour_channels=3):\n",
        "        super(CardCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d( colour_channels, 32, kernel_size=3, padding=1),  # Input 3x128x128\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # 32x64x64\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # 64x32x32\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 * 32 * 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "fgep8pE79528"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nUsing device: {f\"\\033[32m{device}\\033[0m\" if torch.cuda.is_available() else f\"{device}\"} \\n\")\n",
        "model = CardCNN(num_classes=len(dataset.classes), colour_channels=3).to(device)      #default 3 (RGB), change to 1 for grayscale\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if l_r == \"\":\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "else:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=l_r)"
      ],
      "metadata": {
        "id": "EWeirY4--DSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d =0\n",
        "start_time = time.time()\n",
        "print(f\"\\033[32mtraining started...\\033[0m \\ndetails:\\n lr count: {l_r}\\n epoch count: {epc}\\n\")\n",
        "\n",
        "try:\n",
        "    for epoch in range(epc):\n",
        "        print(f\"\\033[33mEpoch: {epoch+1}\\033[0m\")\n",
        "        t = time.time()\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for images, labels in dataloader:\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print(f\"  loss: {loss.item()}\")\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch - {epoch+1}:\\n Total loss: {total_loss:.4f}\")\n",
        "        t = (time.time() - t)\n",
        "        print(f\" time taken for epoch {epoch+1}: {(t)} seconds\")\n",
        "        d +=t\n",
        "\n",
        "    print(f\"\\n\\033[32mTraining completed in {time.time() - start_time:.2f} seconds \\nAverage time per epoch: {(d)/epc}\\033[0m\")\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{save_model_name}.pth\")\n",
        "    print(f\"model saved as: {save_model_name}.pth\")\n",
        "except Exception as e:\n",
        "    print(f\"error: {e}\")"
      ],
      "metadata": {
        "id": "6TRdLftz-ErN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing/Prediction"
      ],
      "metadata": {
        "id": "qMZAKu4Ngme5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#incase you didn't run training phase\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "TPnzp7scgmG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformer = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),   # Resize to uniform size\n",
        "    transforms.ToTensor(),           # Convert to tensor\n",
        "])"
      ],
      "metadata": {
        "id": "95k4_kmahF2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classes = ['ace of clubs', 'ace of diamonds', 'ace of hearts', 'ace of spades', 'eight of clubs', 'eight of diamonds', 'eight of hearts', 'eight of spades', 'five of clubs', 'five of diamonds', 'five of hearts', 'five of spades', 'four of clubs', 'four of diamonds', 'four of hearts', 'four of spades', 'jack of clubs', 'jack of diamonds', 'jack of hearts', 'jack of spades', 'joker', 'king of clubs', 'king of diamonds', 'king of hearts', 'king of spades', 'nine of clubs', 'nine of diamonds', 'nine of hearts', 'nine of spades', 'queen of clubs', 'queen of diamonds', 'queen of hearts', 'queen of spades', 'seven of clubs', 'seven of diamonds', 'seven of hearts', 'seven of spades', 'six of clubs', 'six of diamonds', 'six of hearts', 'six of spades', 'ten of clubs', 'ten of diamonds', 'ten of hearts', 'ten of spades', 'three of clubs', 'three of diamonds', 'three of hearts', 'three of spades', 'two of clubs', 'two of diamonds', 'two of hearts', 'two of spades']\n",
        "dataset = datasets.ImageFolder(root=\"dataset\", transform=img_transformer)\n",
        "# you get the point...\n",
        "#print(\"Classes:\", classes)\n",
        "print(\"Classes:\", dataset.classes)"
      ],
      "metadata": {
        "id": "odsRCKashNav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CardCNN(nn.Module):                                   # Make sure this matches the original training model class\n",
        "    def __init__(self, num_classes, colour_channels= 3):\n",
        "        super(CardCNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(colour_channels, 32, kernel_size=3, padding=1),     # Input 3x128x128\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                                # 32x64x64\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                                # 64x32x32\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 * 32 * 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "epzTUYDZhXMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nUsing device: {f\"\\033[32m{device}\\033[0m\" if torch.cuda.is_available() else f\"{device}\"} \\n\")\n",
        "\n",
        "model = CardCNN(num_classes=len(dataset.classes), colour_channels=3).to(device)           # Make sure this matches the original training model and change colour channels if you have to\n"
      ],
      "metadata": {
        "id": "jaPpFUJkhbJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "image = Image.open(\"test.png\").convert(\"RGB\")               # Replace with your image\n",
        "image = img_transformer(image).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    images.to(device)\n",
        "    output = model(image)\n",
        "    predicted_index = output.argmax(1).item()\n",
        "\n",
        "print(f\"\\033[32mPredicted class: {dataset.classes[predicted_index]}\\033[0m\")\n",
        "\n",
        "image = Image.open(\"test1.jpg\").convert(\"RGB\")               # Replace with your image\n",
        "image = img_transformer(image).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    predicted_index = output.argmax(1).item()\n",
        "print(f\"\\033[32mPredicted class: {dataset.classes[predicted_index]}\\033[0m\")"
      ],
      "metadata": {
        "id": "DTV9SKhahhO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation Phase"
      ],
      "metadata": {
        "id": "d3bc8sipcuQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transforms + dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root = \"dataset\", transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "xf2r1cz85uB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nUsing device: {f\"\\033[32m{device}\\033[0m\" if f\"{device}\"==\"cuda\" else f\"{device}\"} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rvDVuPgDEys",
        "outputId": "a8de32c7-6f38-4d3d-900c-5407bdd7c8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using device: \u001b[32mcuda\u001b[0m \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CardCNN(num_classes=len(test_dataset.classes), colour_channels=3)      # same architecture as training change colour channels if you have to\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(\"model1.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "zGAyQFqact1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "wrong = 0\n",
        "total = 0\n",
        "batch_no = 0\n",
        "total_loss = 0\n",
        "print(\"Evaluating accuracy of the mmodel...\")\n",
        "print(f\"\\nUsing device: {f\"\\033[32m{device}\\033[0m\" if f\"{device}\" == \"cuda\" else f\"{device}\"} \\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():                           # disables gradient calculation (faster, less memory)\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)    # get class with highest probability\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        batch_no+=1\n",
        "        print(f\"batch: {batch_no+1}\")\n",
        "\n",
        "\n",
        "print(f\"\\nTotal images: {total}\\nCorrect predictions: {f\"\\033[32m{correct}\\033[0m\" if ((100 * correct / total) >=98.0)  else (f\"\\033[31m{correct}\\033[0m\" if((100 * correct / total)<=60.0) else f\"{correct}\")}  \\nAverage loss (per image): {total_loss/total}\")\n",
        "print(f\"Accuracy of the model: { f\"\\033[32m{(100 * correct / total)}%\\033[0m\" if ((100 * correct / total) >=98.0)  else (f\"\\033[31m{(100 * correct / total)}%\\033[0m\" if((100 * correct / total)<=60.0) else f\"{(100 * correct / total)}%\" )}\")\n",
        "print(f\"\\n\\033[32mEvaluation completed in {time.time() - start_time:.2f} seconds\\033[0m\")"
      ],
      "metadata": {
        "id": "WbOwE8v06zDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AbZj47HM9-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}